// lib/screens/camera_screen.dart
import 'dart:typed_data';
import 'dart:convert';
import 'dart:async';

import 'package:flutter/material.dart';
import 'package:camera/camera.dart';
import 'package:http/http.dart' as http;
import 'package:http_parser/http_parser.dart';

import '../camera/macro_profile_storage.dart';
import '../camera/camera_orchestrator.dart';
import '../camera/live_sharpness_analyzer.dart';
import '../widgets/camera_overlay.dart';
import 'summary_screen.dart';

const String kAiBaseUrl = String.fromEnvironment(
  'AI_BASE_URL',
  defaultValue: 'http://172.20.10.11:8000',
);

class CameraScreen extends StatefulWidget {
  final String examId;
  final int age;
  final String gender;

  const CameraScreen({
    Key? key,
    required this.examId,
    required this.age,
    required this.gender,
  }) : super(key: key);

  @override
  State<CameraScreen> createState() => _CameraScreenState();
}

class _CameraScreenState extends State<CameraScreen> {
  CameraOrchestrator? _orchestrator;
  CameraController? _controller;

  Uint8List? _left;
  Uint8List? _right;

  bool _leftDone = false;
  bool _rightDone = false;

  bool _initializing = true;
  bool _capturing = false;
  bool _sending = false;

  LiveSharpnessAnalyzer? _sharp;

  double _liveSharpness = 0.0;
  double _adaptiveThreshold = 0.0;
  bool _stable = false;
  bool _readyFrame = false;
  bool _calibrated = false;

  bool get ready => _leftDone && _rightDone;

  @override
  void initState() {
    super.initState();
    _initPipeline();
  }

  @override
  void dispose() {
    _controller?.dispose();
    _sharp?.dispose();
    super.dispose();
  }

  Future<void> _initPipeline() async {
    try {
      final cams = await availableCameras();

      CameraDescription selectedCamera = cams.firstWhere(
        (c) => c.lensDirection == CameraLensDirection.back,
        orElse: () => cams.first,
      );

      final telephoto = cams.where(
        (c) =>
            c.lensDirection == CameraLensDirection.back &&
            c.name.toLowerCase().contains("tele"),
      );
      if (telephoto.isNotEmpty) {
        selectedCamera = telephoto.first;
      }

      final tmp = CameraController(
        selectedCamera,
        ResolutionPreset.max,
        enableAudio: false,
        imageFormatGroup: ImageFormatGroup.yuv420,
      );
      await tmp.initialize();

      final storage = MacroProfileStorage();
      final profile = await storage.loadOrCreateProfile(tmp);

      await tmp.dispose();

      _sharp = LiveSharpnessAnalyzer(profile: profile);

      final orch = CameraOrchestrator(profile);
      await orch.initialize();

      final controller = orch.controller;
      if (controller == null) {
        throw "Camera not initialized";
      }

      try {
        await controller.setFocusMode(FocusMode.auto);
      } catch (_) {}

      await _startStream(controller);

      _sharp!.stream.listen((data) {
        if (!mounted) return;
        setState(() {
          _liveSharpness = data["sharpness"] ?? 0.0;
          _adaptiveThreshold = data["threshold"] ?? 0.0;
          _stable = data["stable"] ?? false;
          _readyFrame = data["ready"] ?? false;
          _calibrated = data["calibrated"] ?? false;
        });
      });

      if (!mounted) return;
      setState(() {
        _orchestrator = orch;
        _controller = controller;
        _initializing = false;
      });
    } catch (e) {
      if (!mounted) return;
      setState(() => _initializing = false);
      ScaffoldMessenger.of(context).showSnackBar(
        SnackBar(content: Text("Ошибка камеры: $e")),
      );
    }
  }

  Future<void> _startStream(CameraController controller) async {
    if (controller.value.isStreamingImages) {
      try {
        await controller.stopImageStream();
      } catch (_) {}
      await Future.delayed(const Duration(milliseconds: 120));
    }

    await controller.startImageStream((CameraImage frame) {
      _sharp?.handleCameraImage(frame);
    });
  }

  Future<void> _capture(String side) async {
    if (_controller == null || _orchestrator == null || _capturing || _sending) return;

    setState(() => _capturing = true);

    try {
      if (!_readyFrame || !_stable || !_calibrated) {
        throw "Кадр ещё не стабилен. Резкость: ${_liveSharpness.toStringAsFixed(1)}, "
            "порог: ${_adaptiveThreshold.toStringAsFixed(1)}";
      }

      try {
        if (_controller!.value.isStreamingImages) {
          await _controller!.stopImageStream();
        }
      } catch (_) {}
      await Future.delayed(const Duration(milliseconds: 120));

      final best = await _orchestrator!.captureBestIris();

      setState(() {
        if (side == "left") {
          _left = best;
          _leftDone = true;
        } else {
          _right = best;
          _rightDone = true;
        }
      });

      await _startStream(_controller!);
    } catch (e) {
      if (!mounted) return;
      ScaffoldMessenger.of(context).showSnackBar(
        SnackBar(content: Text("$e")),
      );
    } finally {
      if (mounted) setState(() => _capturing = false);
    }
  }

  Uri _aiEndpoint() {
    final raw = kAiBaseUrl.trim();
    if (raw.contains("/analyze-eye")) return Uri.parse(raw);
    final base = raw.replaceAll(RegExp(r'/+$'), '');
    return Uri.parse("$base/analyze-eye");
  }

  Future<Map<String, dynamic>> _postOneEye({
    required String side,
    required Uint8List bytes,
  }) async {
    final req = http.MultipartRequest("POST", _aiEndpoint());

    req.fields["exam_id"] = widget.examId;
    req.fields["age"] = widget.age.toString();
    req.fields["gender"] = widget.gender;
    req.fields["side"] = side;
    req.fields["locale"] = "ru";
    req.fields["task"] = "Iridodiagnosis";

    req.files.add(
      http.MultipartFile.fromBytes(
        "file",
        bytes,
        filename: "${widget.examId}_$side.jpg",
        contentType: MediaType("image", "jpeg"),
      ),
    );

    final streamed = await req.send().timeout(const Duration(seconds: 60));
    final resp = await http.Response.fromStream(streamed);

    if (resp.statusCode < 200 || resp.statusCode >= 300) {
      throw "Server error: ${resp.statusCode} ${resp.body}";
    }

    final decoded = json.decode(resp.body);
    if (decoded is Map<String, dynamic>) return decoded;
    return {"raw": decoded};
  }

  Future<void> _sendForAnalysis() async {
    if (!ready || _sending) return;
    if (_left == null || _right == null) return;

    setState(() => _sending = true);

    try {
      final leftResp = await _postOneEye(side: "left", bytes: _left!);
      final rightResp = await _postOneEye(side: "right", bytes: _right!);

      if (!mounted) return;
      Navigator.push(
        context,
        MaterialPageRoute(
          builder: (_) => SummaryScreen(
            examId: widget.examId,
            left: leftResp,
            right: rightResp,
          ),
        ),
      );
    } catch (e) {
      if (!mounted) return;
      ScaffoldMessenger.of(context).showSnackBar(
        SnackBar(content: Text("Ошибка сервера: $e")),
      );
    } finally {
      if (mounted) setState(() => _sending = false);
    }
  }

  @override
  Widget build(BuildContext context) {
    if (_initializing) {
      return const Scaffold(
        body: Center(child: CircularProgressIndicator()),
      );
    }

    if (_controller == null || !_controller!.value.isInitialized) {
      return const Scaffold(
        body: Center(child: Text("Камера не инициализирована")),
      );
    }

    final ok = _readyFrame && _calibrated && _liveSharpness >= _adaptiveThreshold;

    return Scaffold(
      appBar: AppBar(title: Text("Съёмка (${widget.examId})")),
      body: Column(
        children: [
          Expanded(
            child: Stack(
              children: [
                CameraPreview(_controller!),
                const IrisOverlay(),
                Positioned(
                  bottom: 12,
                  left: 12,
                  child: Container(
                    padding: const EdgeInsets.all(8),
                    decoration: BoxDecoration(
                      color: ok
                          ? Colors.green.withOpacity(0.75)
                          : Colors.red.withOpacity(0.75),
                      borderRadius: BorderRadius.circular(8),
                    ),
                    child: Text(
                      "Резкость: ${_liveSharpness.toStringAsFixed(1)} / ${_adaptiveThreshold.toStringAsFixed(1)}\n"
                      "Калибровка: ${_calibrated ? "да" : "нет"}\n"
                      "Стабильно: ${_stable ? "да" : "нет"}",
                      style: const TextStyle(
                        color: Colors.white,
                        fontSize: 15,
                        fontWeight: FontWeight.bold,
                      ),
                    ),
                  ),
                ),
              ],
            ),
          ),
          const SizedBox(height: 16),
          Row(
            mainAxisAlignment: MainAxisAlignment.spaceEvenly,
            children: [
              ElevatedButton(
                onPressed: _capturing || _sending ? null : () => _capture("left"),
                child: Text(_leftDone ? "Левый ✓" : "Снять левый"),
              ),
              ElevatedButton(
                onPressed: _capturing || _sending ? null : () => _capture("right"),
                child: Text(_rightDone ? "Правый ✓" : "Снять правый"),
              ),
            ],
          ),
          const SizedBox(height: 16),
          ElevatedButton(
            onPressed: ready && !_capturing && !_sending ? _sendForAnalysis : null,
            child: Text(_sending ? "Отправка..." : "Отправить на анализ"),
          ),
          const SizedBox(height: 20),
        ],
      ),
    );
  }
}
